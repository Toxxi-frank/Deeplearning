{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "second.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNonyMoHdozGZNuTLpXqDvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Toxxi-frank/Deeplearning/blob/main/Anti_Deepfake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPzaCAi5c09o",
        "outputId": "c777acd1-751a-4317-869f-70ab969500e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttxSgbH4e09n"
      },
      "source": [
        "4/1AX4XfWi7fZ2sinYWYankoAOIcu4siadAZep5ic4r-3gSABS_IQNj95EsymQ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "2HdNxJXJdYxF",
        "outputId": "2705dcca-7472-4ec2-a6f1-2830f79e550f"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from math import floor\n",
        "\n",
        "# Path to directory where the downloaded data is\n",
        "DATA_DIR = \"/content/drive/MyDrive/DATN/deepfake_database/deepfake_database\"\n",
        "# Path to directory where new dataset should be created\n",
        "TARGET_DIR = \"/content/drive/MyDrive/DATN/dataset\"\n",
        "\n",
        "# Name of the sub-directory containing real images in DATA_DIR\n",
        "REAL_DIR = \"real\"\n",
        "# Name of the sub-directory containing fake images in DATA_DIR\n",
        "FAKE_DIR = \"df\"\n",
        "# Amount of data that should be put in the test set\n",
        "PROP = 0.10\n",
        "\n",
        "\n",
        "def create_target_dirs():\n",
        "    r_train = os.path.join(TARGET_DIR, \"train\", REAL_DIR)\n",
        "    f_train = os.path.join(TARGET_DIR, \"train\", FAKE_DIR)\n",
        "\n",
        "    os.makedirs(r_train)\n",
        "    os.makedirs(f_train)\n",
        "\n",
        "    r_test = os.path.join(TARGET_DIR, \"test\", REAL_DIR)\n",
        "    f_test = os.path.join(TARGET_DIR, \"test\", FAKE_DIR)\n",
        "\n",
        "    os.makedirs(r_test)\n",
        "    os.makedirs(f_test)\n",
        "\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(DATA_DIR):\n",
        "        raise FileNotFoundError(f\"{DATA_DIR} does not exist\")\n",
        "\n",
        "    if not os.path.isdir(DATA_DIR):\n",
        "        raise NotADirectoryError(f\"{DATA_DIR} is not a directory\")\n",
        "\n",
        "    shutil.rmtree(TARGET_DIR, ignore_errors=True)\n",
        "\n",
        "    path = os.path.join(DATA_DIR, \"**\", \"*.jpg\")\n",
        "    imgs = glob.glob(path, recursive=True)\n",
        "\n",
        "    num_imgs = len(imgs)\n",
        "\n",
        "    test_size = floor(len(imgs) * PROP)\n",
        "    train_size = num_imgs - test_size\n",
        "\n",
        "    while True:\n",
        "        print(f\"Creating directories at {TARGET_DIR}....\")\n",
        "        create_target_dirs()\n",
        "        selected = random.sample(imgs, test_size)\n",
        "\n",
        "        train_r_len = len(\n",
        "            [1 for img in imgs if REAL_DIR in img and img not in selected]\n",
        "        )\n",
        "        train_f_len = train_size - train_r_len\n",
        "        test_r_len = len([1 for img in selected if REAL_DIR in img])\n",
        "        test_f_len = test_size - test_r_len\n",
        "\n",
        "        print(f\"Found {num_imgs} images in {DATA_DIR}....\")\n",
        "        print(f\"Copying {train_size} files to {TARGET_DIR}/train/....\")\n",
        "        print(f\"Copying {test_size} files to {TARGET_DIR}/test/....\")\n",
        "        print(\n",
        "            f\"The training set will have {train_r_len} real images and {train_f_len} fake images....\"\n",
        "        )\n",
        "        print(\n",
        "            f\"The test set will have {test_r_len} real images and {test_f_len} fake images...\"\n",
        "        )\n",
        "\n",
        "        for img in imgs:\n",
        "            leaf_dir = REAL_DIR if REAL_DIR in img else FAKE_DIR\n",
        "            intr_dir = \"test\" if img in selected else \"train\"\n",
        "            dst = os.path.join(TARGET_DIR, intr_dir, leaf_dir)\n",
        "            shutil.copy(img, dst)\n",
        "\n",
        "        prompt = input(\"Try again? [Yy/Nn] \")\n",
        "        if prompt in [\"n\", \"N\"]:\n",
        "            print(\"Exiting....\")\n",
        "            break\n",
        "\n",
        "        print(\"\\n\\nTrying again....\")\n",
        "        print(f\"Deleting {TARGET_DIR}....\\n\")\n",
        "        shutil.rmtree(TARGET_DIR)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating directories at /content/drive/MyDrive/DATN/dataset....\n",
            "Found 19456 images in /content/drive/MyDrive/DATN/deepfake_database/deepfake_database....\n",
            "Copying 17511 files to /content/drive/MyDrive/DATN/dataset/train/....\n",
            "Copying 1945 files to /content/drive/MyDrive/DATN/dataset/test/....\n",
            "The training set will have 10391 real images and 7120 fake images....\n",
            "The test set will have 1117 real images and 828 fake images...\n",
            "Creating directories at /content/drive/MyDrive/DATN/dataset....\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6ba309e66c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \"\"\"\n\u001b[1;32m     89\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-6ba309e66c57>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating directories at {TARGET_DIR}....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcreate_target_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6ba309e66c57>\u001b[0m in \u001b[0;36mcreate_target_dirs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAKE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/DATN/dataset/train/real'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAkL_dv-qDJZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCy2--nhg8eG"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Conv2D, ReLU, ELU, LeakyReLU, Dropout, Dense, MaxPooling2D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "from math import floor, log\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy5A0ozZg9PW"
      },
      "source": [
        "IMG_WIDTH = 256"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6yKGNDAg_rg"
      },
      "source": [
        "def get_datagen(use_default_augmentation=True, **kwargs):\n",
        "    kwargs.update({'rescale': 1./255})\n",
        "    if use_default_augmentation:\n",
        "        kwargs.update({\n",
        "            'rotation_range': 15,\n",
        "            'zoom_range': 0.2,\n",
        "            'brightness_range': (0.8, 1.2),\n",
        "            'channel_shift_range': 30,\n",
        "            'horizontal_flip': True,\n",
        "        })\n",
        "    return ImageDataGenerator(**kwargs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u893gfqQhC1r"
      },
      "source": [
        "def get_train_data_generator(\n",
        "    train_data_dir, \n",
        "    batch_size, \n",
        "    validation_split=None, \n",
        "    use_default_augmentation=True,\n",
        "    augmentations=None\n",
        "):\n",
        "    if not augmentations:\n",
        "        augmentations = {}\n",
        "\n",
        "    train_datagen = get_datagen(\n",
        "        use_default_augmentation=use_default_augmentation,\n",
        "        validation_split=validation_split if validation_split else 0.0,\n",
        "        **augmentations\n",
        "    )\n",
        "   \n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        directory=train_data_dir,\n",
        "        target_size=(IMG_WIDTH, IMG_WIDTH),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        subset='training',\n",
        "    )\n",
        "\n",
        "    validation_generator = None\n",
        "\n",
        "    if validation_split:\n",
        "        validation_generator = train_datagen.flow_from_directory(\n",
        "            directory=train_data_dir,\n",
        "            target_size=(IMG_WIDTH, IMG_WIDTH),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='binary',\n",
        "            subset='validation'\n",
        "        )\n",
        "\n",
        "    return train_generator, validation_generator"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz2RcrfhhF-L"
      },
      "source": [
        "def get_test_data_generator(test_data_dir, batch_size, shuffle=False):\n",
        "    test_datagen = get_datagen(use_default_augmentation=False)\n",
        "    return test_datagen.flow_from_directory(\n",
        "        directory=test_data_dir,\n",
        "        target_size=(IMG_WIDTH, IMG_WIDTH),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        shuffle=shuffle\n",
        "    )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc5RBzN_hIDc"
      },
      "source": [
        "def activation_layer(ip, activation, *args):\n",
        "    return {'relu': ReLU(*args)(ip),\n",
        "            'elu': ELU(*args)(ip),\n",
        "            'lrelu': LeakyReLU(*args)(ip)}[activation]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYQqGUxZhLh6"
      },
      "source": [
        "def conv2D(ip,\n",
        "           filters,\n",
        "           kernel_size,\n",
        "           activation,\n",
        "           padding='same',\n",
        "           pool_size=(2, 2)):\n",
        "    layer = Conv2D(filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   padding=padding)(ip)\n",
        "\n",
        "    layer = activation_layer(layer, activation=activation)\n",
        "\n",
        "    layer = BatchNormalization()(layer)\n",
        "\n",
        "    return MaxPooling2D(pool_size=pool_size, padding=padding)(layer)\n",
        "\n",
        "def fully_connected_layer(ip,\n",
        "                          hidden_activation,\n",
        "                          dropout):\n",
        "    layer = Dense(16)(ip)\n",
        "    layer = activation_layer(layer, hidden_activation, *[0.1,])\n",
        "    return Dropout(rate=dropout)(layer)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ-tyfWGhNqj"
      },
      "source": [
        "def build_model(ip=Input(shape=(IMG_WIDTH, IMG_WIDTH, 3)),\n",
        "                activation='relu',\n",
        "                dropout=0.5,\n",
        "                hidden_activation='lrelu'):\n",
        "    \n",
        "    layer = conv2D(ip, filters=8, kernel_size=(3, 3), activation=activation)\n",
        "\n",
        "    layer = conv2D(layer, filters=8, kernel_size=(5, 5), activation=activation)\n",
        "\n",
        "    layer = conv2D(layer, filters=16, kernel_size=(5, 5), activation=activation)\n",
        "\n",
        "    layer = conv2D(layer, filters=16, kernel_size=(5, 5), activation=activation, pool_size=(4, 4))\n",
        "\n",
        "    layer = Flatten()(layer)\n",
        "    layer = Dropout(rate=dropout)(layer)\n",
        "\n",
        "    layer = fully_connected_layer(layer, hidden_activation=hidden_activation, dropout=dropout)\n",
        "\n",
        "    op_layer = Dense(1, activation='sigmoid')(layer)\n",
        "\n",
        "    model = Model(ip, op_layer)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Rc2mVyhQeE"
      },
      "source": [
        "def evaluate_model(model, test_data_dir, batch_size):\n",
        "    data = get_test_data_generator(test_data_dir, batch_size)\n",
        "    return model.evaluate(data)\n",
        "\n",
        "\n",
        "def predict(model, data, steps=None, threshold=0.5):\n",
        "    predictions = model.predict(data, steps=steps, verbose=1)\n",
        "    return predictions, np.where(predictions >= threshold, 1, 0)\n",
        "\n",
        "\n",
        "def save_model_history(history, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(history.history, f)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub4kB9BjhQn4"
      },
      "source": [
        "def get_activation_model(model, conv_idx):\n",
        "    conv_layers = [layer for layer in model.layers if 'conv' in layer.name]\n",
        "    selected_layers = [layer for index, layer in enumerate(conv_layers) if index in conv_idx]\n",
        "    activation_model = Model(\n",
        "        inputs=model.inputs,\n",
        "        outputs=[layer.output for layer in selected_layers]\n",
        "    )\n",
        "    return activation_model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXHarh1ihUVd"
      },
      "source": [
        "def plot_loss_curve(history):\n",
        "    plt.plot(history.history['loss'], 'r', label='train')\n",
        "    plt.plot(history.history['val_loss'], 'g', label='validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "def get_classification_report(\n",
        "    model, data_dir, batch_size=64,\n",
        "    steps=None, threshold=0.5, output_dict=False\n",
        "):\n",
        "    data = get_test_data_generator(data_dir, batch_size=batch_size)\n",
        "    predictions = predict(model, data, steps, threshold)\n",
        "    predictions = predictions.reshape((predictions.shape[0],))\n",
        "    return classification_report(data.classes, predictions, output_dict=output_dict)\n",
        "def visualize_conv_layers_single_img(\n",
        "    activations,\n",
        "    conv_idx,\n",
        "):\n",
        "    images_per_row = 4\n",
        "\n",
        "    for activation, idx in zip(activations, conv_idx):\n",
        "        num_filters = activation.shape[-1]\n",
        "\n",
        "        imgs = [activation[:, :, i] for i in range(num_filters)]\n",
        "\n",
        "        num_rows = num_filters // images_per_row\n",
        "\n",
        "        fig = plt.figure()\n",
        "        grid = ImageGrid(fig, 111, (num_rows, images_per_row))\n",
        "\n",
        "        for ax, im in zip(grid, imgs):\n",
        "            ax.imshow(im, cmap='viridis')\n",
        "\n",
        "        plt.title(f'Convolutional Layer {idx + 1}')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def visualize_conv_layers(model, imgs, conv_idx):\n",
        "    activation_model = get_activation_model(model, conv_idx)\n",
        "    activations = activation_model.predict(imgs)\n",
        "\n",
        "    num_imgs = imgs.shape[0]\n",
        "    num_layers = len(conv_idx)\n",
        "\n",
        "    for idx in range(num_imgs):\n",
        "        img_activs = [activations[i][idx, :, :, :] for i in range(num_layers)]\n",
        "        visualize_conv_layers_single_img(\n",
        "            activations=img_activs, conv_idx=conv_idx\n",
        "        )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riEn_gE1hW2p"
      },
      "source": [
        "def train_model(model,\n",
        "                train_data_dir,\n",
        "                validation_split=None,\n",
        "                batch_size=32,\n",
        "                use_default_augmentation=True,\n",
        "                augmentations=None,\n",
        "                epochs=30,\n",
        "                lr=1e-3,\n",
        "                loss='binary_crossentropy',\n",
        "                compile=True,\n",
        "                lr_decay=True,\n",
        "                decay_rate=0.10,\n",
        "                decay_limit=1e-6,\n",
        "                checkpoint=True,\n",
        "                stop_early=True,\n",
        "                monitor='val_accuracy',\n",
        "                mode='max',\n",
        "                patience=20,\n",
        "                tensorboard=True,\n",
        "                loss_curve=True):\n",
        "    \n",
        "    run_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    train_generator, validation_generator = get_train_data_generator(\n",
        "        train_data_dir=train_data_dir,\n",
        "        batch_size=batch_size,\n",
        "        validation_split=validation_split,\n",
        "        use_default_augmentation=use_default_augmentation,\n",
        "        augmentations=augmentations\n",
        "    )\n",
        "\n",
        "    callbacks = []\n",
        "    if checkpoint:\n",
        "        filepath = f'run_{run_time}_best_model.hdf5'\n",
        "        model_checkpoint = ModelCheckpoint(\n",
        "            filepath, monitor='val_accuracy', verbose=1,\n",
        "            save_best_only=True\n",
        "        )\n",
        "        callbacks.append(model_checkpoint)\n",
        "\n",
        "    if stop_early:\n",
        "        callbacks.append(\n",
        "            EarlyStopping(\n",
        "                monitor=monitor,\n",
        "                mode=mode,\n",
        "                patience=patience,\n",
        "                verbose=1\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if tensorboard:\n",
        "        log_dir = \"logs/fit/\" + run_time\n",
        "        callbacks.append(TensorBoard(log_dir, histogram_freq=1, write_images=True))\n",
        "\n",
        "    if compile:\n",
        "        if lr_decay:\n",
        "            num_times = floor(log(decay_limit / lr, decay_rate))\n",
        "            per_epoch = epochs // num_times\n",
        "            lr = ExponentialDecay(\n",
        "                lr,\n",
        "                decay_steps=(train_generator.samples // batch_size) * per_epoch,\n",
        "                decay_rate=decay_rate,\n",
        "                staircase=True,\n",
        "            )\n",
        "        optimizer = Adam(learning_rate=lr)\n",
        "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "        callbacks=callbacks,\n",
        "        validation_data=validation_generator,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        validation_steps=validation_generator.samples // batch_size if validation_generator else None,\n",
        "    )\n",
        "\n",
        "    if loss_curve:\n",
        "        plot_loss_curve(history)\n",
        "\n",
        "    return history"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eucVvaihZ3p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "274c5b65-57d4-4d2d-bbe1-a53028fa644c"
      },
      "source": [
        "def main():\n",
        "    train_data_dir = '/content/drive/MyDrive/DATN/dataset/train'# need changed\n",
        "    val_split, epochs, batch_size = 0.20, 50, 64\n",
        "    decay_rate, decay_limit = 0.10, 1e-6\n",
        "    model = build_model()\n",
        "    return model, train_model(\n",
        "        model,\n",
        "        train_data_dir,\n",
        "        validation_split=val_split,\n",
        "        epochs=epochs,\n",
        "        decay_rate=decay_rate,\n",
        "        decay_limit=decay_limit\n",
        "    )\n",
        "\n",
        "# !rm -rf logs\n",
        "# %tensorboard --logdir logs/fit\n",
        "model, history = main()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14009 images belonging to 2 classes.\n",
            "Found 3502 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.5717 - accuracy: 0.7128\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83056, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 308s 684ms/step - loss: 0.5717 - accuracy: 0.7128 - val_loss: 0.4519 - val_accuracy: 0.8306\n",
            "Epoch 2/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8272\n",
            "Epoch 00002: val_accuracy improved from 0.83056 to 0.88188, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 322s 737ms/step - loss: 0.3841 - accuracy: 0.8272 - val_loss: 0.3124 - val_accuracy: 0.8819\n",
            "Epoch 3/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.8539\n",
            "Epoch 00003: val_accuracy did not improve from 0.88188\n",
            "437/437 [==============================] - 298s 683ms/step - loss: 0.3287 - accuracy: 0.8539 - val_loss: 0.3187 - val_accuracy: 0.8664\n",
            "Epoch 4/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.8721\n",
            "Epoch 00004: val_accuracy improved from 0.88188 to 0.89163, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 321s 735ms/step - loss: 0.2987 - accuracy: 0.8721 - val_loss: 0.2797 - val_accuracy: 0.8916\n",
            "Epoch 5/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.8804\n",
            "Epoch 00005: val_accuracy did not improve from 0.89163\n",
            "437/437 [==============================] - 325s 744ms/step - loss: 0.2806 - accuracy: 0.8804 - val_loss: 0.2675 - val_accuracy: 0.8913\n",
            "Epoch 6/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.8915\n",
            "Epoch 00006: val_accuracy improved from 0.89163 to 0.89364, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 322s 738ms/step - loss: 0.2563 - accuracy: 0.8915 - val_loss: 0.2581 - val_accuracy: 0.8936\n",
            "Epoch 7/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.9018\n",
            "Epoch 00007: val_accuracy did not improve from 0.89364\n",
            "437/437 [==============================] - 321s 736ms/step - loss: 0.2447 - accuracy: 0.9018 - val_loss: 0.3076 - val_accuracy: 0.8770\n",
            "Epoch 8/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9028\n",
            "Epoch 00008: val_accuracy did not improve from 0.89364\n",
            "437/437 [==============================] - 323s 740ms/step - loss: 0.2328 - accuracy: 0.9028 - val_loss: 0.2812 - val_accuracy: 0.8653\n",
            "Epoch 9/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9076\n",
            "Epoch 00009: val_accuracy did not improve from 0.89364\n",
            "437/437 [==============================] - 327s 750ms/step - loss: 0.2257 - accuracy: 0.9076 - val_loss: 0.2609 - val_accuracy: 0.8830\n",
            "Epoch 10/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.9053\n",
            "Epoch 00010: val_accuracy improved from 0.89364 to 0.89708, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 306s 701ms/step - loss: 0.2219 - accuracy: 0.9053 - val_loss: 0.2243 - val_accuracy: 0.8971\n",
            "Epoch 11/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9109\n",
            "Epoch 00011: val_accuracy improved from 0.89708 to 0.90224, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 302s 692ms/step - loss: 0.2139 - accuracy: 0.9109 - val_loss: 0.2395 - val_accuracy: 0.9022\n",
            "Epoch 12/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9177\n",
            "Epoch 00012: val_accuracy did not improve from 0.90224\n",
            "437/437 [==============================] - 302s 692ms/step - loss: 0.2014 - accuracy: 0.9177 - val_loss: 0.2831 - val_accuracy: 0.8802\n",
            "Epoch 13/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.2025 - accuracy: 0.9168\n",
            "Epoch 00013: val_accuracy improved from 0.90224 to 0.90625, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 324s 742ms/step - loss: 0.2025 - accuracy: 0.9168 - val_loss: 0.2305 - val_accuracy: 0.9062\n",
            "Epoch 14/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9184\n",
            "Epoch 00014: val_accuracy did not improve from 0.90625\n",
            "437/437 [==============================] - 302s 691ms/step - loss: 0.1978 - accuracy: 0.9184 - val_loss: 0.2271 - val_accuracy: 0.9040\n",
            "Epoch 15/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9232\n",
            "Epoch 00015: val_accuracy improved from 0.90625 to 0.90826, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 302s 692ms/step - loss: 0.1907 - accuracy: 0.9232 - val_loss: 0.2213 - val_accuracy: 0.9083\n",
            "Epoch 16/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1876 - accuracy: 0.9247\n",
            "Epoch 00016: val_accuracy did not improve from 0.90826\n",
            "437/437 [==============================] - 326s 746ms/step - loss: 0.1876 - accuracy: 0.9247 - val_loss: 0.2779 - val_accuracy: 0.8905\n",
            "Epoch 17/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.9374\n",
            "Epoch 00017: val_accuracy improved from 0.90826 to 0.91284, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 304s 696ms/step - loss: 0.1623 - accuracy: 0.9374 - val_loss: 0.2027 - val_accuracy: 0.9128\n",
            "Epoch 18/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9408\n",
            "Epoch 00018: val_accuracy improved from 0.91284 to 0.91600, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 327s 750ms/step - loss: 0.1481 - accuracy: 0.9408 - val_loss: 0.2102 - val_accuracy: 0.9160\n",
            "Epoch 19/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9431\n",
            "Epoch 00019: val_accuracy improved from 0.91600 to 0.91829, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 345s 790ms/step - loss: 0.1443 - accuracy: 0.9431 - val_loss: 0.2080 - val_accuracy: 0.9183\n",
            "Epoch 20/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.9432\n",
            "Epoch 00020: val_accuracy did not improve from 0.91829\n",
            "437/437 [==============================] - 331s 757ms/step - loss: 0.1398 - accuracy: 0.9432 - val_loss: 0.1957 - val_accuracy: 0.9157\n",
            "Epoch 21/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9455\n",
            "Epoch 00021: val_accuracy improved from 0.91829 to 0.91886, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 319s 730ms/step - loss: 0.1395 - accuracy: 0.9455 - val_loss: 0.2007 - val_accuracy: 0.9189\n",
            "Epoch 22/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9457\n",
            "Epoch 00022: val_accuracy did not improve from 0.91886\n",
            "437/437 [==============================] - 348s 797ms/step - loss: 0.1379 - accuracy: 0.9457 - val_loss: 0.2081 - val_accuracy: 0.9189\n",
            "Epoch 23/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9463\n",
            "Epoch 00023: val_accuracy did not improve from 0.91886\n",
            "437/437 [==============================] - 336s 770ms/step - loss: 0.1392 - accuracy: 0.9463 - val_loss: 0.2163 - val_accuracy: 0.9126\n",
            "Epoch 24/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9447\n",
            "Epoch 00024: val_accuracy did not improve from 0.91886\n",
            "437/437 [==============================] - 332s 761ms/step - loss: 0.1383 - accuracy: 0.9447 - val_loss: 0.2218 - val_accuracy: 0.9160\n",
            "Epoch 25/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.9499\n",
            "Epoch 00025: val_accuracy did not improve from 0.91886\n",
            "437/437 [==============================] - 330s 757ms/step - loss: 0.1335 - accuracy: 0.9499 - val_loss: 0.2164 - val_accuracy: 0.9103\n",
            "Epoch 26/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.9470\n",
            "Epoch 00026: val_accuracy did not improve from 0.91886\n",
            "437/437 [==============================] - 329s 754ms/step - loss: 0.1322 - accuracy: 0.9470 - val_loss: 0.2165 - val_accuracy: 0.9169\n",
            "Epoch 27/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9502\n",
            "Epoch 00027: val_accuracy did not improve from 0.91886\n",
            "437/437 [==============================] - 308s 705ms/step - loss: 0.1326 - accuracy: 0.9502 - val_loss: 0.2051 - val_accuracy: 0.9171\n",
            "Epoch 28/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9493\n",
            "Epoch 00028: val_accuracy did not improve from 0.91886\n",
            "437/437 [==============================] - 325s 743ms/step - loss: 0.1347 - accuracy: 0.9493 - val_loss: 0.2092 - val_accuracy: 0.9108\n",
            "Epoch 29/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9485\n",
            "Epoch 00029: val_accuracy improved from 0.91886 to 0.92575, saving model to run_20211127-135138_best_model.hdf5\n",
            "437/437 [==============================] - 303s 694ms/step - loss: 0.1317 - accuracy: 0.9485 - val_loss: 0.1885 - val_accuracy: 0.9257\n",
            "Epoch 30/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1314 - accuracy: 0.9492\n",
            "Epoch 00030: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 325s 745ms/step - loss: 0.1314 - accuracy: 0.9492 - val_loss: 0.2013 - val_accuracy: 0.9246\n",
            "Epoch 31/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.9491\n",
            "Epoch 00031: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 327s 748ms/step - loss: 0.1319 - accuracy: 0.9491 - val_loss: 0.2092 - val_accuracy: 0.9186\n",
            "Epoch 32/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.9508\n",
            "Epoch 00032: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 308s 705ms/step - loss: 0.1285 - accuracy: 0.9508 - val_loss: 0.1999 - val_accuracy: 0.9232\n",
            "Epoch 33/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9539\n",
            "Epoch 00033: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 326s 746ms/step - loss: 0.1209 - accuracy: 0.9539 - val_loss: 0.2032 - val_accuracy: 0.9217\n",
            "Epoch 34/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9521\n",
            "Epoch 00034: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 327s 749ms/step - loss: 0.1310 - accuracy: 0.9521 - val_loss: 0.2090 - val_accuracy: 0.9203\n",
            "Epoch 35/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9519\n",
            "Epoch 00035: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 326s 746ms/step - loss: 0.1293 - accuracy: 0.9519 - val_loss: 0.2042 - val_accuracy: 0.9174\n",
            "Epoch 36/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9486\n",
            "Epoch 00036: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 326s 746ms/step - loss: 0.1304 - accuracy: 0.9486 - val_loss: 0.1921 - val_accuracy: 0.9223\n",
            "Epoch 37/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9527\n",
            "Epoch 00037: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 328s 750ms/step - loss: 0.1255 - accuracy: 0.9527 - val_loss: 0.2094 - val_accuracy: 0.9146\n",
            "Epoch 38/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.9543\n",
            "Epoch 00038: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 327s 749ms/step - loss: 0.1276 - accuracy: 0.9543 - val_loss: 0.2046 - val_accuracy: 0.9197\n",
            "Epoch 39/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9513\n",
            "Epoch 00039: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 326s 745ms/step - loss: 0.1269 - accuracy: 0.9513 - val_loss: 0.1986 - val_accuracy: 0.9237\n",
            "Epoch 40/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9527\n",
            "Epoch 00040: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 303s 695ms/step - loss: 0.1259 - accuracy: 0.9527 - val_loss: 0.2065 - val_accuracy: 0.9140\n",
            "Epoch 41/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9536\n",
            "Epoch 00041: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 327s 749ms/step - loss: 0.1234 - accuracy: 0.9536 - val_loss: 0.1941 - val_accuracy: 0.9212\n",
            "Epoch 42/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9532\n",
            "Epoch 00042: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 304s 697ms/step - loss: 0.1234 - accuracy: 0.9532 - val_loss: 0.2074 - val_accuracy: 0.9160\n",
            "Epoch 43/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9525\n",
            "Epoch 00043: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 327s 748ms/step - loss: 0.1226 - accuracy: 0.9525 - val_loss: 0.2019 - val_accuracy: 0.9200\n",
            "Epoch 44/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9514\n",
            "Epoch 00044: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 304s 696ms/step - loss: 0.1275 - accuracy: 0.9514 - val_loss: 0.1971 - val_accuracy: 0.9235\n",
            "Epoch 45/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9515\n",
            "Epoch 00045: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 303s 693ms/step - loss: 0.1245 - accuracy: 0.9515 - val_loss: 0.2034 - val_accuracy: 0.9169\n",
            "Epoch 46/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9523\n",
            "Epoch 00046: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 325s 745ms/step - loss: 0.1268 - accuracy: 0.9523 - val_loss: 0.2077 - val_accuracy: 0.9183\n",
            "Epoch 47/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9526\n",
            "Epoch 00047: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 300s 686ms/step - loss: 0.1242 - accuracy: 0.9526 - val_loss: 0.2117 - val_accuracy: 0.9128\n",
            "Epoch 48/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9541\n",
            "Epoch 00048: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 323s 740ms/step - loss: 0.1245 - accuracy: 0.9541 - val_loss: 0.2049 - val_accuracy: 0.9166\n",
            "Epoch 49/50\n",
            "437/437 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9549\n",
            "Epoch 00049: val_accuracy did not improve from 0.92575\n",
            "437/437 [==============================] - 299s 685ms/step - loss: 0.1160 - accuracy: 0.9549 - val_loss: 0.2000 - val_accuracy: 0.9194\n",
            "Epoch 00049: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQipNDDBnlMC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dTBo2SW8ohT",
        "outputId": "2136696e-f0b7-458d-f2bd-e80da14184ad"
      },
      "source": [
        "evaluate_model(model, '/content/drive/MyDrive/DATN/dataset/test', 64) # need change"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1945 images belonging to 2 classes.\n",
            "31/31 [==============================] - 6s 195ms/step - loss: 0.0906 - accuracy: 0.9650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09062524884939194, 0.965038537979126]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "soOOtKEf8ynu",
        "outputId": "3e3e9a92-b5cb-4428-c245-e41cd6197fe0"
      },
      "source": [
        "print(get_classification_report(model, '/content/drive/MyDrive/DATN/dataset/test')) #need change"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1945 images belonging to 2 classes.\n",
            "31/31 [==============================] - 6s 195ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-96e85b6c241c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_classification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/DATN/dataset/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#need change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-4b07f88eee6b>\u001b[0m in \u001b[0;36mget_classification_report\u001b[0;34m(model, data_dir, batch_size, steps, threshold, output_dict)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3890 into shape (2,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6PIiwG083iL"
      },
      "source": [
        "def get_classification_report(\n",
        "    model, data_dir, batch_size=64,\n",
        "    steps=None, threshold=0.5, output_dict=False\n",
        "):\n",
        "    data = get_test_data_generator(data_dir, batch_size=batch_size)\n",
        "    predictions = predict(model, data, steps, threshold)\n",
        "    \n",
        "    return classification_report(data.classes, predictions, output_dict=output_dict)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2ezlojdvcUc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE8rB16du9ln",
        "outputId": "514728b0-6aab-48f4-cfda-e19ef137fab8"
      },
      "source": [
        "test_data_dir = '/content/drive/MyDrive/DATN/dataset/test'\n",
        "test_set = get_test_data_generator(test_data_dir, batch_size=64)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1945 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so94PN3hngWB",
        "outputId": "903cb02c-76e9-4915-9686-c1ad7353f1ee"
      },
      "source": [
        "y_pred = model.predict_generator(test_set)\n",
        "y_test = test_set.classes"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gih67aXdu6sj",
        "outputId": "5d46836a-7464-4cff-fe58-9156a55910b6"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
        "print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n",
        "print()\n",
        "print(metrics.classification_report(y_test, y_pred > 0.5))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Score: 0.995330184803152\n",
            "AP Score: 0.9965367969451524\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.96       828\n",
            "           1       0.96      0.98      0.97      1117\n",
            "\n",
            "    accuracy                           0.97      1945\n",
            "   macro avg       0.97      0.96      0.96      1945\n",
            "weighted avg       0.97      0.97      0.96      1945\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "lJtTXnt50dSP",
        "outputId": "15fb872e-bfa0-4477-c411-d48ce9205e34"
      },
      "source": [
        "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-835b24cafe32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B08zfivfxB5z",
        "outputId": "ff89a910-8710-485e-f432-5b6212e77aab"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred>0.5).ravel()\n",
        "\n",
        "a = fp / (fp+tn)\n",
        "b = fn / (tp+fn)\n",
        "c = 2*a*b / (a+b)\n",
        "print(a, b, c)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05676328502415459 0.018800358102059087 0.02824559646286148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB8E9v4CxMqZ",
        "outputId": "48421639-f44e-47ff-8e83-158e6202cb68"
      },
      "source": [
        "print(tn, fp, fn, tp)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "781 47 21 1096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "MoFeIIK6x0Ru",
        "outputId": "a09a755a-16d1-4885-933e-2cad2b855278"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr,tpr,_ = roc_curve(y_test, y_pred)\n",
        "plt.plot(fpr,tpr, label='AUC = ' + str(round(roc_auc_score(y,m.oob_decision_function_[:,1]), 2)))\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-97ce05d63ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AUC = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_decision_function_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "N-Ox4jKBzqWh",
        "outputId": "50ffddf3-23c5-4d50-d875-e955cb4cbe43"
      },
      "source": [
        "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred)\n",
        "plt.plot(fpr,tpr,label=\"AUC plot, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs1F7DdExC0J"
      },
      "source": [
        "##Load_pre_trained_weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um46aD9JnpQr"
      },
      "source": [
        "model_exp = load_model('/content/drive/MyDrive/DATN/model1_18epochs_valacc0.9252.hdf5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJiHKEHmn9s0",
        "outputId": "412ff8ce-88cd-4f38-9c43-c6ffd5cc53d5"
      },
      "source": [
        "evaluate_model(model_exp, '/content/drive/MyDrive/DATN/dataset/test', 64) # need change"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1945 images belonging to 2 classes.\n",
            "31/31 [==============================] - 6s 197ms/step - loss: 0.1006 - accuracy: 0.9604\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10064361989498138, 0.9604113101959229]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5hs9GTgn--v",
        "outputId": "98fd3c3f-1233-4d95-b9b0-92af51dca497"
      },
      "source": [
        "y_pred_1 = model_exp.predict_generator(test_set)\n",
        "y_test_1 = test_set.classes"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFKyHmjbwwd9",
        "outputId": "a48218bd-8f3e-41a2-846d-fc1e7768bd6e"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"ROC AUC Score:\", metrics.roc_auc_score(y_test_1, y_pred_1))\n",
        "print(\"AP Score:\", metrics.average_precision_score(y_test_1, y_pred_1))\n",
        "print()\n",
        "print(metrics.classification_report(y_test_1, y_pred_1 > 0.5))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Score: 0.9950912338518895\n",
            "AP Score: 0.9964209445982397\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95       828\n",
            "           1       0.95      0.98      0.97      1117\n",
            "\n",
            "    accuracy                           0.96      1945\n",
            "   macro avg       0.96      0.96      0.96      1945\n",
            "weighted avg       0.96      0.96      0.96      1945\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPn9jacPxS_J",
        "outputId": "516e9287-f820-43db-b2e9-5c6245b9e777"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test_1, y_pred_1>0.5).ravel()\n",
        "\n",
        "a = fp / (fp+tn)\n",
        "b = fn / (tp+fn)\n",
        "c = 2*a*b / (a+b)\n",
        "print(a, b, c)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06884057971014493 0.017905102954341987 0.02841865160976704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ0asmi8xTpn",
        "outputId": "00447e23-a055-42c1-e884-52b4c3bf5237"
      },
      "source": [
        "print(tn, fp, fn, tp)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771 57 20 1097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uGVHS-U30HWC",
        "outputId": "54197e29-3690-4ae5-b6bd-e002768d1997"
      },
      "source": [
        "fpr, tpr, _ = metrics.roc_curve(y_test_1,  y_pred_1)\n",
        "auc = metrics.roc_auc_score(y_test_1, y_pred_1)\n",
        "plt.plot(fpr,tpr,label=\"AUC plot, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}